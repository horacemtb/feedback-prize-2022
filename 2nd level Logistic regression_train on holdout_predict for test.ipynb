{"cells":[{"cell_type":"markdown","metadata":{"id":"2k2ZEsbWUWuf"},"source":["In this notebook, we will train a second-level Logistic Regression model using descriptive text features along with the predictions from the three first-level models: DeBERTa, LSTM, and XGBoost. The holdout dataset will be used for training the second-level model, and the final model's performance will be assessed on the test set."]},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xo9uGax90QTN","executionInfo":{"status":"ok","timestamp":1728393109921,"user_tz":-180,"elapsed":6053,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}},"outputId":"9bb96691-cfdd-4387-cfe6-189f0edff228"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n","Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19037,"status":"ok","timestamp":1728393128948,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"},"user_tz":-180},"id":"45cQ8Eg3K0cA","outputId":"6cc6967e-2ded-4be3-8621-87d50af71168"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3182,"status":"ok","timestamp":1728393250062,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"},"user_tz":-180},"id":"MQjjpH9HK0em"},"outputs":[],"source":["import json\n","import pickle\n","import os\n","import joblib\n","from joblib import dump, load\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_score, recall_score, f1_score, log_loss\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","import optuna\n","\n","from tqdm import tqdm\n","from collections import Counter"]},{"cell_type":"code","source":["pd.set_option('display.max_columns', None)"],"metadata":{"id":"uIDp-jGwbAw3","executionInfo":{"status":"ok","timestamp":1728393250063,"user_tz":-180,"elapsed":3,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UEL0zduEK0jU","executionInfo":{"status":"ok","timestamp":1728393250063,"user_tz":-180,"elapsed":3,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"outputs":[],"source":["BASIC_PATH = '/content/gdrive/MyDrive/ML/projects/feedback-prize/'\n","PREDICTION_DATASETS = '1st_level_preds/'\n","MODEL_PATH = '2nd_level_models/'"]},{"cell_type":"markdown","metadata":{"id":"OIvA168MXFg9"},"source":["We will now load the previously saved predictions from the DeBERTa, LSTM, and XGBoost models, and combine them with the descriptive text features. We'll then split the data into training (holdout data), validation, and test sets for training the second-level Logistic Regression model."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"U_l82muVW33n","executionInfo":{"status":"ok","timestamp":1728393256606,"user_tz":-180,"elapsed":6546,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"outputs":[],"source":["holdout_deberta_preds = pd.read_csv(BASIC_PATH+PREDICTION_DATASETS+'holdout_1st_level_deberta_preds.csv')\n","holdout_lstm_preds = pd.read_csv(BASIC_PATH+PREDICTION_DATASETS+'holdout_1st_level_lstm_preds.csv')\n","holdout_xgb_preds = pd.read_csv(BASIC_PATH+PREDICTION_DATASETS+'holdout_1st_level_xgb_preds.csv')\n","\n","test_deberta_preds = pd.read_csv(BASIC_PATH+PREDICTION_DATASETS+'test_1st_level_deberta_preds.csv')\n","test_lstm_preds = pd.read_csv(BASIC_PATH+PREDICTION_DATASETS+'test_1st_level_lstm_preds.csv')\n","test_xgb_preds = pd.read_csv(BASIC_PATH+PREDICTION_DATASETS+'test_1st_level_xgb_preds.csv')"]},{"cell_type":"code","source":["holdout_deberta_preds.drop(['essay_id', 'target'], axis = 1, inplace = True)\n","holdout_lstm_preds.drop(['essay_id', 'target'], axis = 1, inplace = True)\n","\n","test_deberta_preds.drop(['essay_id', 'target'], axis = 1, inplace = True)\n","test_lstm_preds.drop(['essay_id', 'target'], axis = 1, inplace = True)"],"metadata":{"id":"3CbHjYD12cD6","executionInfo":{"status":"ok","timestamp":1728393256606,"user_tz":-180,"elapsed":3,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_df = holdout_deberta_preds.\\\n","merge(holdout_lstm_preds, on = 'discourse_id', how = 'left').\\\n","merge(holdout_xgb_preds, on = 'discourse_id', how = 'left')\n","\n","test_df = test_deberta_preds.\\\n","merge(test_lstm_preds, on = 'discourse_id', how = 'left').\\\n","merge(test_xgb_preds, on = 'discourse_id', how = 'left')"],"metadata":{"id":"R-bTGCY02KGp","executionInfo":{"status":"ok","timestamp":1728393256606,"user_tz":-180,"elapsed":2,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"8zNv_toBXdae","executionInfo":{"status":"ok","timestamp":1728393258929,"user_tz":-180,"elapsed":458,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"outputs":[],"source":["COLS_TO_DROP = ['discourse_id', 'essay_id', 'target']\n","TARGET = 'target'\n","CAT_FEATURES = ['1st_level_deberta_preds', '1st_level_lstm_preds', '1st_level_xgb_preds', 'discourse_type']\n","NUM_FEATURES = ['discourse_len', 'essay_len']\n","OTHER_FEATURES = ['discourse_num_long_words', 'discourse_num_short_words', 'discourse_noun_count',\n","                  'discourse_adj_count', 'discourse_pnoun_count', 'essay_num_long_words',\n","                  'essay_num_short_words', 'essay_noun_count', 'essay_adj_count', 'essay_pnoun_count']"]},{"cell_type":"markdown","source":["We will extract a slice of essay_ids from the test_data to create a separate validation dataset. This validation set will be used for evaluation during hyperparameter optimization."],"metadata":{"id":"_NhmejEM32S1"}},{"cell_type":"code","source":["test_ids, validation_ids = train_test_split(test_df['essay_id'].unique(), test_size = 0.2, random_state = 77)"],"metadata":{"id":"Nnz8tUuZ3kTK","executionInfo":{"status":"ok","timestamp":1728393260382,"user_tz":-180,"elapsed":298,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["validation_df = test_df[test_df['essay_id'].isin(validation_ids)].copy()\n","test_df = test_df[test_df['essay_id'].isin(test_ids)].copy()\n","\n","validation_df.reset_index(drop = True, inplace = True)\n","test_df.reset_index(drop = True, inplace = True)"],"metadata":{"id":"WDsCAelU4m77","executionInfo":{"status":"ok","timestamp":1728393261610,"user_tz":-180,"elapsed":327,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Preprocess categorical and numerical columns for the model."],"metadata":{"id":"rops7uJkn_PS"}},{"cell_type":"code","source":["y_train = train_df[TARGET]\n","y_val = validation_df[TARGET]\n","y_test = test_df[TARGET]\n","\n","train_df.drop(COLS_TO_DROP, axis = 1, inplace = True)\n","validation_df.drop(COLS_TO_DROP, axis = 1, inplace = True)\n","test_df.drop(COLS_TO_DROP, axis = 1, inplace = True)"],"metadata":{"id":"k5t5IxmORKue","executionInfo":{"status":"ok","timestamp":1728393262381,"user_tz":-180,"elapsed":3,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["preprocessor = ColumnTransformer(\n","    transformers = [\n","        ('cat', OneHotEncoder(drop = 'first'), CAT_FEATURES),\n","        ('num', StandardScaler(), NUM_FEATURES)\n","        ],\n","    remainder = 'passthrough')"],"metadata":{"id":"Cz1iCzgHjNrq","executionInfo":{"status":"ok","timestamp":1728393264746,"user_tz":-180,"elapsed":1253,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["X_train_transformed = preprocessor.fit_transform(train_df)\n","X_validation_transformed = preprocessor.transform(validation_df)"],"metadata":{"id":"JtvOySchRH2O","executionInfo":{"status":"ok","timestamp":1728393266901,"user_tz":-180,"elapsed":300,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["transformed_columns = (\n","    preprocessor\n","    .transformers_[0][1]\n","    .get_feature_names_out(CAT_FEATURES).tolist() +\n","    NUM_FEATURES + OTHER_FEATURES\n",")"],"metadata":{"id":"B19Z8hUxTcv2","executionInfo":{"status":"ok","timestamp":1728393268429,"user_tz":-180,"elapsed":295,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["pd.DataFrame(X_validation_transformed, columns = transformed_columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"n_6WPmU2VVcC","executionInfo":{"status":"ok","timestamp":1728393269678,"user_tz":-180,"elapsed":7,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}},"outputId":"bfb6c0ea-267f-437c-9be1-3b3159635119"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      1st_level_deberta_preds_1  1st_level_deberta_preds_2  \\\n","0                           1.0                        0.0   \n","1                           1.0                        0.0   \n","2                           1.0                        0.0   \n","3                           1.0                        0.0   \n","4                           1.0                        0.0   \n","...                         ...                        ...   \n","1516                        0.0                        0.0   \n","1517                        0.0                        0.0   \n","1518                        1.0                        0.0   \n","1519                        1.0                        0.0   \n","1520                        1.0                        0.0   \n","\n","      1st_level_lstm_preds_1  1st_level_lstm_preds_2  1st_level_xgb_preds_1  \\\n","0                        1.0                     0.0                    1.0   \n","1                        1.0                     0.0                    1.0   \n","2                        1.0                     0.0                    1.0   \n","3                        0.0                     0.0                    1.0   \n","4                        1.0                     0.0                    1.0   \n","...                      ...                     ...                    ...   \n","1516                     0.0                     0.0                    1.0   \n","1517                     0.0                     0.0                    1.0   \n","1518                     0.0                     0.0                    1.0   \n","1519                     1.0                     0.0                    1.0   \n","1520                     1.0                     0.0                    1.0   \n","\n","      1st_level_xgb_preds_2  discourse_type_Concluding Statement  \\\n","0                       0.0                                  0.0   \n","1                       0.0                                  0.0   \n","2                       0.0                                  0.0   \n","3                       0.0                                  0.0   \n","4                       0.0                                  0.0   \n","...                     ...                                  ...   \n","1516                    0.0                                  0.0   \n","1517                    0.0                                  0.0   \n","1518                    0.0                                  0.0   \n","1519                    0.0                                  0.0   \n","1520                    0.0                                  1.0   \n","\n","      discourse_type_Counterclaim  discourse_type_Evidence  \\\n","0                             0.0                      0.0   \n","1                             0.0                      0.0   \n","2                             0.0                      0.0   \n","3                             0.0                      0.0   \n","4                             0.0                      1.0   \n","...                           ...                      ...   \n","1516                          0.0                      0.0   \n","1517                          0.0                      1.0   \n","1518                          0.0                      0.0   \n","1519                          0.0                      1.0   \n","1520                          0.0                      0.0   \n","\n","      discourse_type_Lead  discourse_type_Position  discourse_type_Rebuttal  \\\n","0                     1.0                      0.0                      0.0   \n","1                     0.0                      1.0                      0.0   \n","2                     0.0                      0.0                      0.0   \n","3                     0.0                      0.0                      0.0   \n","4                     0.0                      0.0                      0.0   \n","...                   ...                      ...                      ...   \n","1516                  0.0                      0.0                      0.0   \n","1517                  0.0                      0.0                      0.0   \n","1518                  0.0                      0.0                      0.0   \n","1519                  0.0                      0.0                      0.0   \n","1520                  0.0                      0.0                      0.0   \n","\n","      discourse_len  essay_len  discourse_num_long_words  \\\n","0          1.906488   2.133127                  0.211382   \n","1         -0.566913   2.133127                  0.294118   \n","2         -0.610168   2.133127                  0.250000   \n","3         -0.692746   2.133127                  0.250000   \n","4          6.652744   2.133127                  0.180791   \n","...             ...        ...                       ...   \n","1516      -0.857901   1.669537                  0.250000   \n","1517      -0.161889   1.669537                  0.121951   \n","1518      -0.775324   1.669537                  0.111111   \n","1519       0.321781   1.669537                  0.142857   \n","1520       0.604905   1.669537                  0.178082   \n","\n","      discourse_num_short_words  discourse_noun_count  discourse_adj_count  \\\n","0                      0.471545              0.317073             0.105691   \n","1                      0.411765              0.352941             0.176471   \n","2                      0.312500              0.187500             0.062500   \n","3                      0.583333              0.416667             0.083333   \n","4                      0.559322              0.197740             0.064972   \n","...                         ...                   ...                  ...   \n","1516                   0.250000              0.500000             0.250000   \n","1517                   0.634146              0.121951             0.097561   \n","1518                   0.444444              0.222222             0.222222   \n","1519                   0.555556              0.126984             0.095238   \n","1520                   0.561644              0.150685             0.150685   \n","\n","      discourse_pnoun_count  essay_num_long_words  essay_num_short_words  \\\n","0                       0.0              0.213421               0.525853   \n","1                       0.0              0.213421               0.525853   \n","2                       0.0              0.213421               0.525853   \n","3                       0.0              0.213421               0.525853   \n","4                       0.0              0.213421               0.525853   \n","...                     ...                   ...                    ...   \n","1516                    0.0              0.131579               0.591533   \n","1517                    0.0              0.131579               0.591533   \n","1518                    0.0              0.131579               0.591533   \n","1519                    0.0              0.131579               0.591533   \n","1520                    0.0              0.131579               0.591533   \n","\n","      essay_noun_count  essay_adj_count  essay_pnoun_count  \n","0             0.243124         0.088009           0.005501  \n","1             0.243124         0.088009           0.005501  \n","2             0.243124         0.088009           0.005501  \n","3             0.243124         0.088009           0.005501  \n","4             0.243124         0.088009           0.005501  \n","...                ...              ...                ...  \n","1516          0.141876         0.094966           0.009153  \n","1517          0.141876         0.094966           0.009153  \n","1518          0.141876         0.094966           0.009153  \n","1519          0.141876         0.094966           0.009153  \n","1520          0.141876         0.094966           0.009153  \n","\n","[1521 rows x 24 columns]"],"text/html":["\n","  <div id=\"df-ecaf7e19-eabc-4223-be54-f65610768d17\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>1st_level_deberta_preds_1</th>\n","      <th>1st_level_deberta_preds_2</th>\n","      <th>1st_level_lstm_preds_1</th>\n","      <th>1st_level_lstm_preds_2</th>\n","      <th>1st_level_xgb_preds_1</th>\n","      <th>1st_level_xgb_preds_2</th>\n","      <th>discourse_type_Concluding Statement</th>\n","      <th>discourse_type_Counterclaim</th>\n","      <th>discourse_type_Evidence</th>\n","      <th>discourse_type_Lead</th>\n","      <th>discourse_type_Position</th>\n","      <th>discourse_type_Rebuttal</th>\n","      <th>discourse_len</th>\n","      <th>essay_len</th>\n","      <th>discourse_num_long_words</th>\n","      <th>discourse_num_short_words</th>\n","      <th>discourse_noun_count</th>\n","      <th>discourse_adj_count</th>\n","      <th>discourse_pnoun_count</th>\n","      <th>essay_num_long_words</th>\n","      <th>essay_num_short_words</th>\n","      <th>essay_noun_count</th>\n","      <th>essay_adj_count</th>\n","      <th>essay_pnoun_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.906488</td>\n","      <td>2.133127</td>\n","      <td>0.211382</td>\n","      <td>0.471545</td>\n","      <td>0.317073</td>\n","      <td>0.105691</td>\n","      <td>0.0</td>\n","      <td>0.213421</td>\n","      <td>0.525853</td>\n","      <td>0.243124</td>\n","      <td>0.088009</td>\n","      <td>0.005501</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>-0.566913</td>\n","      <td>2.133127</td>\n","      <td>0.294118</td>\n","      <td>0.411765</td>\n","      <td>0.352941</td>\n","      <td>0.176471</td>\n","      <td>0.0</td>\n","      <td>0.213421</td>\n","      <td>0.525853</td>\n","      <td>0.243124</td>\n","      <td>0.088009</td>\n","      <td>0.005501</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-0.610168</td>\n","      <td>2.133127</td>\n","      <td>0.250000</td>\n","      <td>0.312500</td>\n","      <td>0.187500</td>\n","      <td>0.062500</td>\n","      <td>0.0</td>\n","      <td>0.213421</td>\n","      <td>0.525853</td>\n","      <td>0.243124</td>\n","      <td>0.088009</td>\n","      <td>0.005501</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-0.692746</td>\n","      <td>2.133127</td>\n","      <td>0.250000</td>\n","      <td>0.583333</td>\n","      <td>0.416667</td>\n","      <td>0.083333</td>\n","      <td>0.0</td>\n","      <td>0.213421</td>\n","      <td>0.525853</td>\n","      <td>0.243124</td>\n","      <td>0.088009</td>\n","      <td>0.005501</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.652744</td>\n","      <td>2.133127</td>\n","      <td>0.180791</td>\n","      <td>0.559322</td>\n","      <td>0.197740</td>\n","      <td>0.064972</td>\n","      <td>0.0</td>\n","      <td>0.213421</td>\n","      <td>0.525853</td>\n","      <td>0.243124</td>\n","      <td>0.088009</td>\n","      <td>0.005501</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1516</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-0.857901</td>\n","      <td>1.669537</td>\n","      <td>0.250000</td>\n","      <td>0.250000</td>\n","      <td>0.500000</td>\n","      <td>0.250000</td>\n","      <td>0.0</td>\n","      <td>0.131579</td>\n","      <td>0.591533</td>\n","      <td>0.141876</td>\n","      <td>0.094966</td>\n","      <td>0.009153</td>\n","    </tr>\n","    <tr>\n","      <th>1517</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-0.161889</td>\n","      <td>1.669537</td>\n","      <td>0.121951</td>\n","      <td>0.634146</td>\n","      <td>0.121951</td>\n","      <td>0.097561</td>\n","      <td>0.0</td>\n","      <td>0.131579</td>\n","      <td>0.591533</td>\n","      <td>0.141876</td>\n","      <td>0.094966</td>\n","      <td>0.009153</td>\n","    </tr>\n","    <tr>\n","      <th>1518</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-0.775324</td>\n","      <td>1.669537</td>\n","      <td>0.111111</td>\n","      <td>0.444444</td>\n","      <td>0.222222</td>\n","      <td>0.222222</td>\n","      <td>0.0</td>\n","      <td>0.131579</td>\n","      <td>0.591533</td>\n","      <td>0.141876</td>\n","      <td>0.094966</td>\n","      <td>0.009153</td>\n","    </tr>\n","    <tr>\n","      <th>1519</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.321781</td>\n","      <td>1.669537</td>\n","      <td>0.142857</td>\n","      <td>0.555556</td>\n","      <td>0.126984</td>\n","      <td>0.095238</td>\n","      <td>0.0</td>\n","      <td>0.131579</td>\n","      <td>0.591533</td>\n","      <td>0.141876</td>\n","      <td>0.094966</td>\n","      <td>0.009153</td>\n","    </tr>\n","    <tr>\n","      <th>1520</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.604905</td>\n","      <td>1.669537</td>\n","      <td>0.178082</td>\n","      <td>0.561644</td>\n","      <td>0.150685</td>\n","      <td>0.150685</td>\n","      <td>0.0</td>\n","      <td>0.131579</td>\n","      <td>0.591533</td>\n","      <td>0.141876</td>\n","      <td>0.094966</td>\n","      <td>0.009153</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1521 rows × 24 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecaf7e19-eabc-4223-be54-f65610768d17')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ecaf7e19-eabc-4223-be54-f65610768d17 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ecaf7e19-eabc-4223-be54-f65610768d17');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cd4346ed-67d0-49b0-9b14-9cf5dabf9060\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd4346ed-67d0-49b0-9b14-9cf5dabf9060')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cd4346ed-67d0-49b0-9b14-9cf5dabf9060 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["Configure Optuna optimization and initiate the search for optimal hyperparameters."],"metadata":{"id":"GVOVL6Ge4qsG"}},{"cell_type":"code","source":["def objective(trial):\n","\n","    penalty = trial.suggest_categorical('penalty', ['l2', 'elasticnet', 'l1'])\n","    C = trial.suggest_float('C', 1e-4, 1e2, log = True)\n","    l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n","\n","    model = LogisticRegression(\n","        penalty = penalty,\n","        C = C,\n","        l1_ratio = l1_ratio,\n","        solver = 'saga',\n","        max_iter = 1000,\n","        random_state = 97\n","    )\n","\n","    model.fit(X_train_transformed, y_train)\n","    val_preds = model.predict_proba(X_validation_transformed)\n","\n","    return log_loss(y_val, val_preds)"],"metadata":{"id":"UYR2ByeuqstU","executionInfo":{"status":"ok","timestamp":1728393293839,"user_tz":-180,"elapsed":282,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["study = optuna.create_study(direction = 'minimize', study_name = 'LogReg parameters')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oHEqRCAh03kZ","executionInfo":{"status":"ok","timestamp":1728393296106,"user_tz":-180,"elapsed":567,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}},"outputId":"f80c7e5c-017a-4af8-b3d5-8a0a9318ce0f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-10-08 13:14:54,297] A new study created in memory with name: LogReg parameters\n"]}]},{"cell_type":"code","source":["def callback(study, trial):\n","  pbar.update(1)"],"metadata":{"id":"-osVk7di2Q6M","executionInfo":{"status":"ok","timestamp":1728393297339,"user_tz":-180,"elapsed":340,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["N_trials = 200\n","\n","with tqdm(total = N_trials, desc = \"Optuna Optimization\", dynamic_ncols = True, bar_format = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]') as pbar:\n","    study.optimize(objective, n_trials = N_trials, callbacks = [callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0o9KYy-03nT","executionInfo":{"status":"ok","timestamp":1728393933561,"user_tz":-180,"elapsed":635108,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}},"outputId":"f70e7e5a-7b89-4449-ad01-9d4cfb5cf776"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["\rOptuna Optimization:   0%|          | 0/200 [00:00<?]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:15:10,920] Trial 0 finished with value: 0.7132072657428062 and parameters: {'penalty': 'elasticnet', 'C': 85.90915510729018, 'l1_ratio': 0.16321712364000374}. Best is trial 0 with value: 0.7132072657428062.\n","Optuna Optimization:   0%|          | 1/200 [00:13<45:20]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:15:11,013] Trial 1 finished with value: 0.7276195059954488 and parameters: {'penalty': 'l1', 'C': 0.011570432497351835, 'l1_ratio': 0.6837687815599354}. Best is trial 0 with value: 0.7132072657428062.\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:15:17,386] Trial 2 finished with value: 0.7119283818750393 and parameters: {'penalty': 'l2', 'C': 11.698876475697332, 'l1_ratio': 0.8694673409936721}. Best is trial 2 with value: 0.7119283818750393.\n","Optuna Optimization:   2%|▏         | 3/200 [00:20<19:30]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:15:17,609] Trial 3 finished with value: 0.7091926291241677 and parameters: {'penalty': 'l1', 'C': 0.13709858927801774, 'l1_ratio': 0.6229429841101539}. Best is trial 3 with value: 0.7091926291241677.\n","Optuna Optimization:   2%|▏         | 4/200 [00:20<12:56][I 2024-10-08 13:15:17,973] Trial 4 finished with value: 0.7082792582257978 and parameters: {'penalty': 'elasticnet', 'C': 0.09778976797090903, 'l1_ratio': 0.18223407661411928}. Best is trial 4 with value: 0.7082792582257978.\n","Optuna Optimization:   2%|▎         | 5/200 [00:20<09:00]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:15:18,068] Trial 5 finished with value: 0.8232821316180806 and parameters: {'penalty': 'l1', 'C': 0.003250807162274625, 'l1_ratio': 0.030983148809131222}. Best is trial 4 with value: 0.7082792582257978.\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:15:24,130] Trial 6 finished with value: 0.7120368975952613 and parameters: {'penalty': 'elasticnet', 'C': 8.288707010344861, 'l1_ratio': 0.6634802338307532}. Best is trial 4 with value: 0.7082792582257978.\n","Optuna Optimization:   4%|▎         | 7/200 [00:26<09:23]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:25,273] Trial 7 finished with value: 0.7083397115373198 and parameters: {'penalty': 'l2', 'C': 0.6994337483148131, 'l1_ratio': 0.3726809489184172}. Best is trial 4 with value: 0.7082792582257978.\n","Optuna Optimization:   4%|▍         | 8/200 [00:28<07:52]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:15:33,388] Trial 8 finished with value: 0.7124885072345062 and parameters: {'penalty': 'l1', 'C': 8.726886677980342, 'l1_ratio': 0.9733350288915261}. Best is trial 4 with value: 0.7082792582257978.\n","Optuna Optimization:   4%|▍         | 9/200 [00:36<12:40][I 2024-10-08 13:15:33,410] Trial 9 finished with value: 0.9756184253228323 and parameters: {'penalty': 'elasticnet', 'C': 0.00011988780218671553, 'l1_ratio': 0.7064067620836681}. Best is trial 4 with value: 0.7082792582257978.\n","[I 2024-10-08 13:15:33,525] Trial 10 finished with value: 0.7480509702015101 and parameters: {'penalty': 'elasticnet', 'C': 0.0037802639604578216, 'l1_ratio': 0.3177885853526398}. Best is trial 4 with value: 0.7082792582257978.\n","Optuna Optimization:   6%|▌         | 11/200 [00:36<07:11]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:34,089] Trial 11 finished with value: 0.7080066781392482 and parameters: {'penalty': 'l2', 'C': 0.24696203296630306, 'l1_ratio': 0.3600443112363436}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:   6%|▌         | 12/200 [00:36<05:52]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:34,520] Trial 12 finished with value: 0.7080254950188773 and parameters: {'penalty': 'l2', 'C': 0.16214265858084123, 'l1_ratio': 0.3137482396696709}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:   6%|▋         | 13/200 [00:37<04:42]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:35,371] Trial 13 finished with value: 0.708130426620732 and parameters: {'penalty': 'l2', 'C': 0.4572001747558388, 'l1_ratio': 0.41210909648461874}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:   7%|▋         | 14/200 [00:38<04:08]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:35,564] Trial 14 finished with value: 0.7095993205507762 and parameters: {'penalty': 'l2', 'C': 0.031246700851784586, 'l1_ratio': 0.5082657318442204}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:   8%|▊         | 15/200 [00:38<03:08]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:36,992] Trial 15 finished with value: 0.7086005070696997 and parameters: {'penalty': 'l2', 'C': 0.9893989746225582, 'l1_ratio': 0.21886853258840694}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:   8%|▊         | 16/200 [00:39<03:28]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:37,067] Trial 16 finished with value: 0.7844865592957483 and parameters: {'penalty': 'l2', 'C': 0.0008288026322532557, 'l1_ratio': 0.5034373132118428}. Best is trial 11 with value: 0.7080066781392482.\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:39,073] Trial 17 finished with value: 0.7092183672377211 and parameters: {'penalty': 'l2', 'C': 1.7575173354602682, 'l1_ratio': 0.07388149799714783}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:   9%|▉         | 18/200 [00:41<03:18]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:39,430] Trial 18 finished with value: 0.7081121647049164 and parameters: {'penalty': 'l2', 'C': 0.11406711084470753, 'l1_ratio': 0.27315311928376595}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  10%|▉         | 19/200 [00:42<02:45]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:39,684] Trial 19 finished with value: 0.708700153684775 and parameters: {'penalty': 'l2', 'C': 0.05167316401631124, 'l1_ratio': 0.4186574622464845}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  10%|█         | 20/200 [00:42<02:14]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:39,829] Trial 20 finished with value: 0.7112730559905037 and parameters: {'penalty': 'l2', 'C': 0.018833075409646505, 'l1_ratio': 0.5767302580551931}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  10%|█         | 21/200 [00:42<01:44]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:40,303] Trial 21 finished with value: 0.7080165009389288 and parameters: {'penalty': 'l2', 'C': 0.1739032269197743, 'l1_ratio': 0.2542528018816912}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  11%|█         | 22/200 [00:43<01:38]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:41,098] Trial 22 finished with value: 0.7080258603914497 and parameters: {'penalty': 'l2', 'C': 0.3002731379139709, 'l1_ratio': 0.2845207515342529}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  12%|█▏        | 23/200 [00:43<01:50]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:45,748] Trial 23 finished with value: 0.7101433118769411 and parameters: {'penalty': 'l2', 'C': 3.380961601229048, 'l1_ratio': 0.11543578922033951}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  12%|█▏        | 24/200 [00:48<05:13]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:46,334] Trial 24 finished with value: 0.7080122146688188 and parameters: {'penalty': 'l2', 'C': 0.26695081969687495, 'l1_ratio': 0.34173578638953817}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  12%|█▎        | 25/200 [00:49<04:10]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:48,811] Trial 25 finished with value: 0.7097602305818779 and parameters: {'penalty': 'l2', 'C': 2.6140621623822486, 'l1_ratio': 0.4278560111124669}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  13%|█▎        | 26/200 [00:51<05:03]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:15:53,107] Trial 26 finished with value: 0.712979872839731 and parameters: {'penalty': 'l2', 'C': 46.51252294204311, 'l1_ratio': 0.23103726365923208}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  14%|█▎        | 27/200 [00:55<07:12]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:53,851] Trial 27 finished with value: 0.7080240771775012 and parameters: {'penalty': 'l2', 'C': 0.2965249703311664, 'l1_ratio': 0.3852279026651513}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  14%|█▍        | 28/200 [00:56<05:39]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:53,941] Trial 28 finished with value: 0.7190306800697331 and parameters: {'penalty': 'l2', 'C': 0.006938507765752614, 'l1_ratio': 0.13333726358517506}. Best is trial 11 with value: 0.7080066781392482.\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:15:54,146] Trial 29 finished with value: 0.7118604499219119 and parameters: {'penalty': 'l1', 'C': 0.045868323001712744, 'l1_ratio': 0.5494580910623739}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  15%|█▌        | 30/200 [00:56<03:13][I 2024-10-08 13:15:57,803] Trial 30 finished with value: 0.708691329193587 and parameters: {'penalty': 'elasticnet', 'C': 1.0735556218988793, 'l1_ratio': 0.1953033663810492}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  16%|█▌        | 31/200 [01:00<04:57]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:58,967] Trial 31 finished with value: 0.7080382565365427 and parameters: {'penalty': 'l2', 'C': 0.32431518777921287, 'l1_ratio': 0.37776516134676}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  16%|█▌        | 32/200 [01:01<04:29]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:15:59,997] Trial 32 finished with value: 0.7080113310164777 and parameters: {'penalty': 'l2', 'C': 0.2644854573661226, 'l1_ratio': 0.46006564400352334}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  16%|█▋        | 33/200 [01:02<04:01]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:16:00,266] Trial 33 finished with value: 0.7086001159457969 and parameters: {'penalty': 'l2', 'C': 0.056198715790989104, 'l1_ratio': 0.4697827965479754}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  17%|█▋        | 34/200 [01:03<03:05]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:16:00,392] Trial 34 finished with value: 0.7123399422266785 and parameters: {'penalty': 'l2', 'C': 0.015165292391092508, 'l1_ratio': 0.343297808019416}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  18%|█▊        | 35/200 [01:03<02:17]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:16:00,697] Trial 35 finished with value: 0.7089755944581987 and parameters: {'penalty': 'l1', 'C': 0.18950747274527505, 'l1_ratio': 0.7757787505712495}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  18%|█▊        | 36/200 [01:03<01:51]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:16:01,038] Trial 36 finished with value: 0.7082747345915159 and parameters: {'penalty': 'l2', 'C': 0.08187550899850703, 'l1_ratio': 0.48042859129914983}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  18%|█▊        | 37/200 [01:03<01:34]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:16:04,089] Trial 37 finished with value: 0.7103694696119063 and parameters: {'penalty': 'l2', 'C': 3.9199144313664323, 'l1_ratio': 0.2510924473265233}. Best is trial 11 with value: 0.7080066781392482.\n","Optuna Optimization:  19%|█▉        | 38/200 [01:06<03:32]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:16:06,974] Trial 38 finished with value: 0.7072228969423837 and parameters: {'penalty': 'l1', 'C': 0.502317535665962, 'l1_ratio': 0.5790584663115392}. Best is trial 38 with value: 0.7072228969423837.\n","Optuna Optimization:  20%|█▉        | 39/200 [01:09<04:46]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:16:14,966] Trial 39 finished with value: 0.7129509151979546 and parameters: {'penalty': 'l1', 'C': 17.945253489115505, 'l1_ratio': 0.5745463370868582}. Best is trial 38 with value: 0.7072228969423837.\n","Optuna Optimization:  20%|██        | 40/200 [01:17<09:40]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:16:20,768] Trial 40 finished with value: 0.7076139145905809 and parameters: {'penalty': 'l1', 'C': 0.9050798624119981, 'l1_ratio': 0.6581401644222618}. Best is trial 38 with value: 0.7072228969423837.\n","Optuna Optimization:  20%|██        | 41/200 [01:23<11:19]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:16:24,717] Trial 41 finished with value: 0.7074358590482065 and parameters: {'penalty': 'l1', 'C': 0.6598629752908337, 'l1_ratio': 0.7334239934865047}. Best is trial 38 with value: 0.7072228969423837.\n","Optuna Optimization:  21%|██        | 42/200 [01:27<11:00]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:16:30,120] Trial 42 finished with value: 0.7075911635951708 and parameters: {'penalty': 'l1', 'C': 0.7311385543689783, 'l1_ratio': 0.7587453758465499}. Best is trial 38 with value: 0.7072228969423837.\n","Optuna Optimization:  22%|██▏       | 43/200 [01:32<11:53]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:16:35,900] Trial 43 finished with value: 0.7092674822028435 and parameters: {'penalty': 'l1', 'C': 1.7649197323117847, 'l1_ratio': 0.7652794851928684}. Best is trial 38 with value: 0.7072228969423837.\n","Optuna Optimization:  22%|██▏       | 44/200 [01:38<12:46]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:16:38,822] Trial 44 finished with value: 0.7072064793620056 and parameters: {'penalty': 'l1', 'C': 0.511132764424568, 'l1_ratio': 0.8467732051019947}. Best is trial 44 with value: 0.7072064793620056.\n","Optuna Optimization:  22%|██▎       | 45/200 [01:41<11:09]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:16:44,243] Trial 45 finished with value: 0.7074462368014534 and parameters: {'penalty': 'l1', 'C': 0.6644196715867502, 'l1_ratio': 0.8735184802299802}. Best is trial 44 with value: 0.7072064793620056.\n","Optuna Optimization:  23%|██▎       | 46/200 [01:46<11:55]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:16:50,095] Trial 46 finished with value: 0.7119806292925053 and parameters: {'penalty': 'l1', 'C': 5.508907849883691, 'l1_ratio': 0.9074644411944529}. Best is trial 44 with value: 0.7072064793620056.\n","Optuna Optimization:  24%|██▎       | 47/200 [01:52<12:46]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:16:53,319] Trial 47 finished with value: 0.7073084239445716 and parameters: {'penalty': 'l1', 'C': 0.5929589574226625, 'l1_ratio': 0.8004430100095274}. Best is trial 44 with value: 0.7072064793620056.\n","Optuna Optimization:  24%|██▍       | 48/200 [01:56<11:19]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:17:01,419] Trial 48 finished with value: 0.712983056693384 and parameters: {'penalty': 'l1', 'C': 19.279973918746474, 'l1_ratio': 0.8461058784479455}. Best is trial 44 with value: 0.7072064793620056.\n","Optuna Optimization:  24%|██▍       | 49/200 [02:04<13:59]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:17:07,182] Trial 49 finished with value: 0.7090701917885328 and parameters: {'penalty': 'l1', 'C': 1.6678966955865722, 'l1_ratio': 0.9880121263155509}. Best is trial 44 with value: 0.7072064793620056.\n","Optuna Optimization:  25%|██▌       | 50/200 [02:09<14:03]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:17:09,887] Trial 50 finished with value: 0.707416070918672 and parameters: {'penalty': 'l1', 'C': 0.42812901006123855, 'l1_ratio': 0.8401804878370396}. Best is trial 44 with value: 0.7072064793620056.\n","Optuna Optimization:  26%|██▌       | 51/200 [02:12<11:47]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:17:13,255] Trial 51 finished with value: 0.7073815695880548 and parameters: {'penalty': 'l1', 'C': 0.43854267685739345, 'l1_ratio': 0.8875578607526172}. Best is trial 44 with value: 0.7072064793620056.\n","Optuna Optimization:  26%|██▌       | 52/200 [02:16<10:41]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:17:16,204] Trial 52 finished with value: 0.7071973406497343 and parameters: {'penalty': 'l1', 'C': 0.516326825650216, 'l1_ratio': 0.8115980510472388}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  26%|██▋       | 53/200 [02:18<09:35]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:17:16,424] Trial 53 finished with value: 0.7096856745978101 and parameters: {'penalty': 'l1', 'C': 0.09826424674670496, 'l1_ratio': 0.8191623012172465}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  27%|██▋       | 54/200 [02:19<06:50]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:17:17,941] Trial 54 finished with value: 0.7075266778140624 and parameters: {'penalty': 'l1', 'C': 0.3991623061297742, 'l1_ratio': 0.9187151760531151}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  28%|██▊       | 55/200 [02:20<05:51]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:17:21,212] Trial 55 finished with value: 0.7073351704791717 and parameters: {'penalty': 'l1', 'C': 0.6074040874605182, 'l1_ratio': 0.9405495249367417}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  28%|██▊       | 56/200 [02:23<06:25]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:17:29,201] Trial 56 finished with value: 0.7082641176718342 and parameters: {'penalty': 'l1', 'C': 1.3096288556992366, 'l1_ratio': 0.9553675830289238}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  28%|██▊       | 57/200 [02:31<10:10]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:17:35,060] Trial 57 finished with value: 0.7121285112604039 and parameters: {'penalty': 'l1', 'C': 6.187667798906864, 'l1_ratio': 0.8054343143178796}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  29%|██▉       | 58/200 [02:37<11:14]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:17:42,986] Trial 58 finished with value: 0.7104192123072433 and parameters: {'penalty': 'l1', 'C': 2.5794051231882316, 'l1_ratio': 0.8999399605042266}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  30%|██▉       | 59/200 [02:45<13:23][I 2024-10-08 13:17:45,852] Trial 59 finished with value: 0.7073130872611063 and parameters: {'penalty': 'elasticnet', 'C': 0.5492337790240899, 'l1_ratio': 0.9524718418728167}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  30%|███       | 60/200 [02:48<11:19][I 2024-10-08 13:17:46,129] Trial 60 finished with value: 0.7090270182981351 and parameters: {'penalty': 'elasticnet', 'C': 0.1556799051028112, 'l1_ratio': 0.9588001173880002}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  30%|███       | 61/200 [02:48<08:03][I 2024-10-08 13:17:49,113] Trial 61 finished with value: 0.707542464711097 and parameters: {'penalty': 'elasticnet', 'C': 0.6639601008144951, 'l1_ratio': 0.9373927800842248}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  31%|███       | 62/200 [02:51<07:39][I 2024-10-08 13:17:52,004] Trial 62 finished with value: 0.7072225842545907 and parameters: {'penalty': 'elasticnet', 'C': 0.5051779638024784, 'l1_ratio': 0.990993952186605}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  32%|███▏      | 63/200 [02:54<07:18][I 2024-10-08 13:17:55,483] Trial 63 finished with value: 0.7076414916040802 and parameters: {'penalty': 'elasticnet', 'C': 0.5306828187929976, 'l1_ratio': 0.6822734533207359}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  32%|███▏      | 64/200 [02:58<07:26]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:18:01,810] Trial 64 finished with value: 0.708189856710558 and parameters: {'penalty': 'elasticnet', 'C': 1.275905222200849, 'l1_ratio': 0.9977865600831317}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  32%|███▎      | 65/200 [03:04<09:26]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:18:08,937] Trial 65 finished with value: 0.7099167240430999 and parameters: {'penalty': 'elasticnet', 'C': 2.1640515413022787, 'l1_ratio': 0.8618364604039855}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  33%|███▎      | 66/200 [03:11<11:20][I 2024-10-08 13:18:09,036] Trial 66 finished with value: 0.9748957118744698 and parameters: {'penalty': 'elasticnet', 'C': 0.0006504556688975047, 'l1_ratio': 0.9345248523362842}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  34%|███▎      | 67/200 [03:11<07:56][I 2024-10-08 13:18:10,408] Trial 67 finished with value: 0.7085811407625001 and parameters: {'penalty': 'elasticnet', 'C': 0.2093783721007936, 'l1_ratio': 0.7995902297628958}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  34%|███▍      | 68/200 [03:13<06:25][I 2024-10-08 13:18:10,736] Trial 68 finished with value: 0.7124170129881108 and parameters: {'penalty': 'elasticnet', 'C': 0.02898041710165354, 'l1_ratio': 0.642355401926409}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  34%|███▍      | 69/200 [03:13<04:40]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:11,006] Trial 69 finished with value: 0.7100618012921579 and parameters: {'penalty': 'l1', 'C': 0.08340140666832903, 'l1_ratio': 0.7133631798261513}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  35%|███▌      | 70/200 [03:13<03:25]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:18:16,855] Trial 70 finished with value: 0.7113744995051035 and parameters: {'penalty': 'l1', 'C': 3.740290645264593, 'l1_ratio': 0.9680791362738967}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  36%|███▌      | 71/200 [03:19<06:08]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:19,758] Trial 71 finished with value: 0.7072039227030164 and parameters: {'penalty': 'l1', 'C': 0.5125874894205203, 'l1_ratio': 0.8599136184659009}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  36%|███▌      | 72/200 [03:22<06:07]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:18:32,341] Trial 72 finished with value: 0.7078989482516523 and parameters: {'penalty': 'l1', 'C': 1.159278567041078, 'l1_ratio': 0.8381002227536527}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  36%|███▋      | 73/200 [03:35<12:14]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:38,622] Trial 73 finished with value: 0.7076276831934951 and parameters: {'penalty': 'l1', 'C': 0.8829574051383884, 'l1_ratio': 0.8870884567039149}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  37%|███▋      | 74/200 [03:41<12:27]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:39,095] Trial 74 finished with value: 0.7091291958932395 and parameters: {'penalty': 'l1', 'C': 0.14671243318077495, 'l1_ratio': 0.9284910698482559}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  38%|███▊      | 75/200 [03:41<08:57][I 2024-10-08 13:18:40,982] Trial 75 finished with value: 0.7075672883977112 and parameters: {'penalty': 'elasticnet', 'C': 0.35378216437360027, 'l1_ratio': 0.7892975157548204}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  38%|███▊      | 76/200 [03:43<07:23]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:44,164] Trial 76 finished with value: 0.7072386097467417 and parameters: {'penalty': 'l1', 'C': 0.5583019755093828, 'l1_ratio': 0.7367888249811442}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  38%|███▊      | 77/200 [03:46<07:05]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:44,960] Trial 77 finished with value: 0.7087381654416192 and parameters: {'penalty': 'l1', 'C': 0.22152701946049227, 'l1_ratio': 0.7346611559909034}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  39%|███▉      | 78/200 [03:47<05:24][I 2024-10-08 13:18:49,324] Trial 78 finished with value: 0.7091500098175415 and parameters: {'penalty': 'elasticnet', 'C': 1.4885185410861708, 'l1_ratio': 0.6252249189013244}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  40%|███▉      | 79/200 [03:52<06:23]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:49,528] Trial 79 finished with value: 0.7095171669054772 and parameters: {'penalty': 'l1', 'C': 0.10901518194546156, 'l1_ratio': 0.8253230510879828}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  40%|████      | 80/200 [03:52<04:33]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:49,765] Trial 80 finished with value: 0.7105959915935938 and parameters: {'penalty': 'l1', 'C': 0.06645473691772406, 'l1_ratio': 0.7554503716395828}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  40%|████      | 81/200 [03:52<03:18]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:54,248] Trial 81 finished with value: 0.7072542332766008 and parameters: {'penalty': 'l1', 'C': 0.48691290324880854, 'l1_ratio': 0.8813595291636357}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  41%|████      | 82/200 [03:56<04:56]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:18:55,823] Trial 82 finished with value: 0.7083039803524056 and parameters: {'penalty': 'l1', 'C': 0.29310380338956593, 'l1_ratio': 0.8725036947834804}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  42%|████▏     | 83/200 [03:58<04:20]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:19:01,634] Trial 83 finished with value: 0.7076023339078523 and parameters: {'penalty': 'l1', 'C': 0.929305211657032, 'l1_ratio': 0.8651731980880474}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  42%|████▏     | 84/200 [04:04<06:23]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:04,268] Trial 84 finished with value: 0.707296075968294 and parameters: {'penalty': 'l1', 'C': 0.46882230300437977, 'l1_ratio': 0.9065241941173636}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  42%|████▎     | 85/200 [04:07<05:56]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:07,481] Trial 85 finished with value: 0.7073862363819794 and parameters: {'penalty': 'l1', 'C': 0.437108405898167, 'l1_ratio': 0.5380466495817422}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  43%|████▎     | 86/200 [04:10<05:57]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:19:14,321] Trial 86 finished with value: 0.709866171261169 and parameters: {'penalty': 'l1', 'C': 2.1247311688857624, 'l1_ratio': 0.8142125868534025}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  44%|████▎     | 87/200 [04:17<07:59]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:14,540] Trial 87 finished with value: 0.7092482260492132 and parameters: {'penalty': 'l1', 'C': 0.13002618620186382, 'l1_ratio': 0.7846344684645729}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  44%|████▍     | 88/200 [04:17<05:40]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:15,454] Trial 88 finished with value: 0.7085626436865553 and parameters: {'penalty': 'l1', 'C': 0.24454307506491607, 'l1_ratio': 0.7035269690884474}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  44%|████▍     | 89/200 [04:18<04:26]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:18,874] Trial 89 finished with value: 0.7076721239424981 and parameters: {'penalty': 'l1', 'C': 0.7814237144589355, 'l1_ratio': 0.8979819805972336}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  45%|████▌     | 90/200 [04:21<04:57]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:19,932] Trial 90 finished with value: 0.7077108214858014 and parameters: {'penalty': 'l1', 'C': 0.36346379688637626, 'l1_ratio': 0.8514290869522643}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  46%|████▌     | 91/200 [04:22<04:01]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:25,205] Trial 91 finished with value: 0.7072836777372903 and parameters: {'penalty': 'l1', 'C': 0.5794796149295636, 'l1_ratio': 0.9757621760196482}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  46%|████▌     | 92/200 [04:27<05:38]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:19:30,961] Trial 92 finished with value: 0.7075933128073225 and parameters: {'penalty': 'l1', 'C': 1.0286420326489434, 'l1_ratio': 0.9846116227597483}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  46%|████▋     | 93/200 [04:33<06:59]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:33,743] Trial 93 finished with value: 0.707241992340921 and parameters: {'penalty': 'l1', 'C': 0.4926993461983755, 'l1_ratio': 0.9238864480301409}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  47%|████▋     | 94/200 [04:36<06:19]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:34,137] Trial 94 finished with value: 0.7089527595946813 and parameters: {'penalty': 'l1', 'C': 0.19819815359633264, 'l1_ratio': 0.912588621559206}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  48%|████▊     | 95/200 [04:36<04:35]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:39,129] Trial 95 finished with value: 0.7072157424220198 and parameters: {'penalty': 'l1', 'C': 0.5061095651136064, 'l1_ratio': 0.8836138369975399}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  48%|████▊     | 96/200 [04:41<05:46]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:40,886] Trial 96 finished with value: 0.7079717033299958 and parameters: {'penalty': 'l1', 'C': 0.3309116003661102, 'l1_ratio': 0.9765214504391732}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  48%|████▊     | 97/200 [04:43<04:54]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:19:46,620] Trial 97 finished with value: 0.7090147071868628 and parameters: {'penalty': 'l1', 'C': 1.6421240403256907, 'l1_ratio': 0.881469258152167}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  49%|████▉     | 98/200 [04:49<06:19]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:19:54,537] Trial 98 finished with value: 0.7107612428914643 and parameters: {'penalty': 'l1', 'C': 2.928432504776146, 'l1_ratio': 0.5913903824911002}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  50%|████▉     | 99/200 [04:57<08:23]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:19:57,762] Trial 99 finished with value: 0.7072438935438102 and parameters: {'penalty': 'l1', 'C': 0.5607869388134873, 'l1_ratio': 0.9987036045679697}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  50%|█████     | 100/200 [05:00<07:25]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:01,749] Trial 100 finished with value: 0.7076595399619979 and parameters: {'penalty': 'l1', 'C': 0.8049152125867005, 'l1_ratio': 0.831897523259405}. Best is trial 52 with value: 0.7071973406497343.\n","Optuna Optimization:  50%|█████     | 101/200 [05:04<07:07]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:06,243] Trial 101 finished with value: 0.707178574793981 and parameters: {'penalty': 'l1', 'C': 0.5276546058877624, 'l1_ratio': 0.9953593630180491}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  51%|█████     | 102/200 [05:08<07:08]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:07,869] Trial 102 finished with value: 0.7084456509664554 and parameters: {'penalty': 'l1', 'C': 0.2646862771422548, 'l1_ratio': 0.9528958951645089}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  52%|█████▏    | 103/200 [05:10<05:43]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:08,153] Trial 103 finished with value: 0.7090044329032511 and parameters: {'penalty': 'l1', 'C': 0.16802956982166237, 'l1_ratio': 0.9988301314252009}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  52%|█████▏    | 104/200 [05:10<04:06]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:20:13,948] Trial 104 finished with value: 0.7082502297603417 and parameters: {'penalty': 'l1', 'C': 1.3030783282425986, 'l1_ratio': 0.9273678312726943}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  52%|█████▎    | 105/200 [05:16<05:35]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:16,788] Trial 105 finished with value: 0.7072270509374571 and parameters: {'penalty': 'l1', 'C': 0.5001507754743652, 'l1_ratio': 0.8537136418202482}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  53%|█████▎    | 106/200 [05:19<05:12]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:22,245] Trial 106 finished with value: 0.7076170883837009 and parameters: {'penalty': 'l1', 'C': 0.7437687101723741, 'l1_ratio': 0.8525904731997427}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  54%|█████▎    | 107/200 [05:24<06:08]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:23,626] Trial 107 finished with value: 0.7078555329062445 and parameters: {'penalty': 'l1', 'C': 0.34361860063100275, 'l1_ratio': 0.9465983340937244}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  54%|█████▍    | 108/200 [05:26<04:53]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:20:29,463] Trial 108 finished with value: 0.7079343699645445 and parameters: {'penalty': 'l1', 'C': 1.1731882798362339, 'l1_ratio': 0.9233953283237858}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  55%|█████▍    | 109/200 [05:32<06:02]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:20:37,395] Trial 109 finished with value: 0.7097539119815851 and parameters: {'penalty': 'l1', 'C': 2.0484986818412514, 'l1_ratio': 0.966014366698187}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  55%|█████▌    | 110/200 [05:40<07:45]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:37,434] Trial 110 finished with value: 0.9759731700833572 and parameters: {'penalty': 'l1', 'C': 0.0001325797961555773, 'l1_ratio': 0.740676496464546}. Best is trial 101 with value: 0.707178574793981.\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:40,216] Trial 111 finished with value: 0.7072481263694164 and parameters: {'penalty': 'l1', 'C': 0.4897706717732904, 'l1_ratio': 0.8949817837173898}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  56%|█████▌    | 112/200 [05:42<05:02]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:43,294] Trial 112 finished with value: 0.7071968848749637 and parameters: {'penalty': 'l1', 'C': 0.5385065464932439, 'l1_ratio': 0.9072437330819413}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  56%|█████▋    | 113/200 [05:46<04:51]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:46,614] Trial 113 finished with value: 0.7074360453196189 and parameters: {'penalty': 'l1', 'C': 0.6599444161577075, 'l1_ratio': 0.9996275852311336}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  57%|█████▋    | 114/200 [05:49<04:47]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:48,248] Trial 114 finished with value: 0.7085393525553985 and parameters: {'penalty': 'l1', 'C': 0.24820290118279423, 'l1_ratio': 0.8627001073506569}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  57%|█████▊    | 115/200 [05:50<04:04]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:55,261] Trial 115 finished with value: 0.707607892314049 and parameters: {'penalty': 'l1', 'C': 0.915614924565507, 'l1_ratio': 0.9096506440383447}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  58%|█████▊    | 116/200 [05:58<05:38]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:56,602] Trial 116 finished with value: 0.70756016561729 and parameters: {'penalty': 'l1', 'C': 0.3914580727884103, 'l1_ratio': 0.011026746767409668}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  58%|█████▊    | 117/200 [05:59<04:30]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:20:56,904] Trial 117 finished with value: 0.7089762165501602 and parameters: {'penalty': 'l1', 'C': 0.1891608843150296, 'l1_ratio': 0.8185882385804982}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  59%|█████▉    | 118/200 [05:59<03:17]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:00,151] Trial 118 finished with value: 0.7072544954599421 and parameters: {'penalty': 'l1', 'C': 0.5657252688209158, 'l1_ratio': 0.7672006932795119}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  60%|█████▉    | 119/200 [06:02<03:34]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:02,538] Trial 119 finished with value: 0.7079744829544933 and parameters: {'penalty': 'l1', 'C': 0.330620138969382, 'l1_ratio': 0.9499356534158092}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  60%|██████    | 120/200 [06:05<03:26]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:02,957] Trial 120 finished with value: 0.7092585210898072 and parameters: {'penalty': 'l1', 'C': 0.12883557038247095, 'l1_ratio': 0.8385620841021333}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  60%|██████    | 121/200 [06:05<02:32]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:07,096] Trial 121 finished with value: 0.7072372873331968 and parameters: {'penalty': 'l1', 'C': 0.49504343857660704, 'l1_ratio': 0.898751170292002}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  61%|██████    | 122/200 [06:09<03:22]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:21:12,844] Trial 122 finished with value: 0.7076367965378578 and parameters: {'penalty': 'l1', 'C': 1.051277058912038, 'l1_ratio': 0.9232149651498647}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  62%|██████▏   | 123/200 [06:15<04:31]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:21:20,959] Trial 123 finished with value: 0.7133478625730632 and parameters: {'penalty': 'l1', 'C': 97.49610930109604, 'l1_ratio': 0.9686365753770513}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  62%|██████▏   | 124/200 [06:23<06:12]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:23,346] Trial 124 finished with value: 0.7073329816681038 and parameters: {'penalty': 'l1', 'C': 0.454786159146409, 'l1_ratio': 0.8778894613227588}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  62%|██████▎   | 125/200 [06:26<05:11]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:26,685] Trial 125 finished with value: 0.7075812090540576 and parameters: {'penalty': 'l1', 'C': 0.7263644542787289, 'l1_ratio': 0.9389178303147372}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  63%|██████▎   | 126/200 [06:29<04:49][I 2024-10-08 13:21:27,941] Trial 126 finished with value: 0.7082186186072355 and parameters: {'penalty': 'elasticnet', 'C': 0.2620410450559359, 'l1_ratio': 0.8531203957560161}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  64%|██████▎   | 127/200 [06:30<03:47]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:21:35,826] Trial 127 finished with value: 0.7084600513575519 and parameters: {'penalty': 'l1', 'C': 1.3980680828208205, 'l1_ratio': 0.7974472282870176}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  64%|██████▍   | 128/200 [06:38<05:27]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:39,066] Trial 128 finished with value: 0.7072621471528875 and parameters: {'penalty': 'l1', 'C': 0.569287917972087, 'l1_ratio': 0.44499988934998136}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  64%|██████▍   | 129/200 [06:41<04:54]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:40,375] Trial 129 finished with value: 0.7075610993405911 and parameters: {'penalty': 'l1', 'C': 0.3912506839641759, 'l1_ratio': 0.8929417370188508}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  65%|██████▌   | 130/200 [06:43<03:50]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:44,977] Trial 130 finished with value: 0.7076450263958336 and parameters: {'penalty': 'l1', 'C': 0.8353115439537492, 'l1_ratio': 0.9821042925623549}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  66%|██████▌   | 131/200 [06:47<04:14]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:49,565] Trial 131 finished with value: 0.7072985002372695 and parameters: {'penalty': 'l1', 'C': 0.46785634149101135, 'l1_ratio': 0.9062270913772515}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  66%|██████▌   | 132/200 [06:52<04:29]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:52,561] Trial 132 finished with value: 0.7071810796176796 and parameters: {'penalty': 'l1', 'C': 0.5260691423305126, 'l1_ratio': 0.8898773349091753}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  66%|██████▋   | 133/200 [06:55<04:05]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:55,844] Trial 133 finished with value: 0.7073339729017909 and parameters: {'penalty': 'l1', 'C': 0.6067587794802628, 'l1_ratio': 0.8667179309781652}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  67%|██████▋   | 134/200 [06:58<03:54]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:21:58,036] Trial 134 finished with value: 0.708188935386711 and parameters: {'penalty': 'l1', 'C': 0.3102168117125416, 'l1_ratio': 0.8196628430238084}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  68%|██████▊   | 135/200 [07:00<03:24]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:22:05,849] Trial 135 finished with value: 0.707599416327839 and parameters: {'penalty': 'l1', 'C': 0.9409243586096384, 'l1_ratio': 0.9320790589988136}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  68%|██████▊   | 136/200 [07:08<04:50][I 2024-10-08 13:22:06,582] Trial 136 finished with value: 0.7086673923107575 and parameters: {'penalty': 'elasticnet', 'C': 0.2031136881974498, 'l1_ratio': 0.8377488474762398}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  68%|██████▊   | 137/200 [07:09<03:34]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:09,877] Trial 137 finished with value: 0.7076046763348366 and parameters: {'penalty': 'l1', 'C': 0.7376721737372414, 'l1_ratio': 0.9580374368610661}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  69%|██████▉   | 138/200 [07:12<03:28]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:10,921] Trial 138 finished with value: 0.7083679004721506 and parameters: {'penalty': 'l1', 'C': 0.2810806982815392, 'l1_ratio': 0.8900734485001539}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  70%|██████▉   | 139/200 [07:13<02:43]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:22:18,840] Trial 139 finished with value: 0.7087302940146656 and parameters: {'penalty': 'l1', 'C': 1.5191297123080094, 'l1_ratio': 0.8714168145723145}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  70%|███████   | 140/200 [07:21<04:14]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:19,965] Trial 140 finished with value: 0.7075962477530454 and parameters: {'penalty': 'l1', 'C': 0.3834456180612709, 'l1_ratio': 0.9815284600530985}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  70%|███████   | 141/200 [07:22<03:15]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:22,635] Trial 141 finished with value: 0.707277503253319 and parameters: {'penalty': 'l1', 'C': 0.4765634071344504, 'l1_ratio': 0.8989773185497795}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  71%|███████   | 142/200 [07:25<03:00]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:25,642] Trial 142 finished with value: 0.7071792013764505 and parameters: {'penalty': 'l1', 'C': 0.5272406619058873, 'l1_ratio': 0.9101002250228054}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  72%|███████▏  | 143/200 [07:28<02:55]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:22:33,590] Trial 143 finished with value: 0.7077534887711027 and parameters: {'penalty': 'l1', 'C': 1.099019554928302, 'l1_ratio': 0.9160668468791449}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  72%|███████▏  | 144/200 [07:36<04:14]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:36,883] Trial 144 finished with value: 0.7073361939582472 and parameters: {'penalty': 'l1', 'C': 0.6079556526946501, 'l1_ratio': 0.8534905302024528}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  72%|███████▎  | 145/200 [07:39<03:49]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:37,876] Trial 145 finished with value: 0.7076181917141886 and parameters: {'penalty': 'l1', 'C': 0.3787588755970339, 'l1_ratio': 0.9454567996936966}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  73%|███████▎  | 146/200 [07:40<02:53]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:41,775] Trial 146 finished with value: 0.7076617864772606 and parameters: {'penalty': 'l1', 'C': 0.801746988746986, 'l1_ratio': 0.9991110643805511}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  74%|███████▎  | 147/200 [07:44<03:01]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:42,056] Trial 147 finished with value: 0.7090330572338434 and parameters: {'penalty': 'l1', 'C': 0.15908786361781352, 'l1_ratio': 0.7778697816843652}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  74%|███████▍  | 148/200 [07:44<02:08][I 2024-10-08 13:22:44,875] Trial 148 finished with value: 0.7076344681288079 and parameters: {'penalty': 'elasticnet', 'C': 0.521254934315228, 'l1_ratio': 0.6779627803792362}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  74%|███████▍  | 149/200 [07:47<02:11]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:46,401] Trial 149 finished with value: 0.7087200251985645 and parameters: {'penalty': 'l1', 'C': 0.2235940513515642, 'l1_ratio': 0.9240043590615228}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  75%|███████▌  | 150/200 [07:49<01:53]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:48,909] Trial 150 finished with value: 0.7081682901039865 and parameters: {'penalty': 'l1', 'C': 0.3120342046123968, 'l1_ratio': 0.8056171529886719}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  76%|███████▌  | 151/200 [07:51<01:54]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:51,648] Trial 151 finished with value: 0.7072485653890772 and parameters: {'penalty': 'l1', 'C': 0.48959066856419076, 'l1_ratio': 0.8823973854282252}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  76%|███████▌  | 152/200 [07:54<01:57]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:22:55,000] Trial 152 finished with value: 0.7075014711359808 and parameters: {'penalty': 'l1', 'C': 0.6892125424886067, 'l1_ratio': 0.9021341763393836}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  76%|███████▋  | 153/200 [07:57<02:08]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:23:02,899] Trial 153 finished with value: 0.7076478117529899 and parameters: {'penalty': 'l1', 'C': 1.0561017966197173, 'l1_ratio': 0.8377295174094677}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  77%|███████▋  | 154/200 [08:05<03:16]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:05,399] Trial 154 finished with value: 0.7073172928360378 and parameters: {'penalty': 'l1', 'C': 0.46058637036153, 'l1_ratio': 0.5280779809087244}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  78%|███████▊  | 155/200 [08:08<02:48]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:08,655] Trial 155 finished with value: 0.7072730582962684 and parameters: {'penalty': 'l1', 'C': 0.5743637403297814, 'l1_ratio': 0.9693044517475382}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  78%|███████▊  | 156/200 [08:11<02:38]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:09,602] Trial 156 finished with value: 0.7077299049221992 and parameters: {'penalty': 'l1', 'C': 0.3604173180087017, 'l1_ratio': 0.8645758408577735}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  78%|███████▊  | 157/200 [08:12<02:00]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:10,545] Trial 157 finished with value: 0.7084822890944613 and parameters: {'penalty': 'l1', 'C': 0.2579674250727508, 'l1_ratio': 0.8872148587331136}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  79%|███████▉  | 158/200 [08:13<01:34]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:17,601] Trial 158 finished with value: 0.7076315532860019 and parameters: {'penalty': 'l1', 'C': 0.8714805227163417, 'l1_ratio': 0.9513255535196681}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  80%|███████▉  | 159/200 [08:20<02:31]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:20,903] Trial 159 finished with value: 0.7073920833320189 and parameters: {'penalty': 'l1', 'C': 0.6382976011968962, 'l1_ratio': 0.9151768684145917}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  80%|████████  | 160/200 [08:23<02:22]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:23:22,692] Trial 160 finished with value: 0.7089665133545451 and parameters: {'penalty': 'l2', 'C': 1.4241983794295394, 'l1_ratio': 0.8240354572194263}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  80%|████████  | 161/200 [08:25<01:58]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:24,811] Trial 161 finished with value: 0.7073693849242422 and parameters: {'penalty': 'l1', 'C': 0.4423620617988061, 'l1_ratio': 0.8907961064776506}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  81%|████████  | 162/200 [08:27<01:44]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:29,000] Trial 162 finished with value: 0.7072123162802565 and parameters: {'penalty': 'l1', 'C': 0.5079607060712114, 'l1_ratio': 0.8796040530360152}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  82%|████████▏ | 163/200 [08:31<01:58]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:31,868] Trial 163 finished with value: 0.7080697194385431 and parameters: {'penalty': 'l1', 'C': 0.32112419646729273, 'l1_ratio': 0.5857980849379677}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  82%|████████▏ | 164/200 [08:34<01:51]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:35,200] Trial 164 finished with value: 0.7075047682036818 and parameters: {'penalty': 'l1', 'C': 0.6907091877325713, 'l1_ratio': 0.8567964917223658}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  82%|████████▎ | 165/200 [08:37<01:50]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:38,091] Trial 165 finished with value: 0.7072182874096831 and parameters: {'penalty': 'l1', 'C': 0.5047274556430305, 'l1_ratio': 0.9304876926675559}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  83%|████████▎ | 166/200 [08:40<01:44]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:23:45,929] Trial 166 finished with value: 0.7075942643349321 and parameters: {'penalty': 'l1', 'C': 0.968323648151615, 'l1_ratio': 0.919139393212932}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  84%|████████▎ | 167/200 [08:48<02:28][I 2024-10-08 13:23:47,507] Trial 167 finished with value: 0.7074924693792565 and parameters: {'penalty': 'elasticnet', 'C': 0.3981471630150785, 'l1_ratio': 0.9421825946215014}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  84%|████████▍ | 168/200 [08:50<01:56]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:48,413] Trial 168 finished with value: 0.7085491557598789 and parameters: {'penalty': 'l1', 'C': 0.24664249783379755, 'l1_ratio': 0.9342651501149414}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  84%|████████▍ | 169/200 [08:51<01:27]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:51,636] Trial 169 finished with value: 0.7072713137546041 and parameters: {'penalty': 'l1', 'C': 0.5735700837917331, 'l1_ratio': 0.9637353307754406}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  85%|████████▌ | 170/200 [08:54<01:28]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:23:55,948] Trial 170 finished with value: 0.7076586792172165 and parameters: {'penalty': 'l1', 'C': 0.8062836667945122, 'l1_ratio': 0.8717618480377619}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  86%|████████▌ | 171/200 [08:58<01:37]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:00,572] Trial 171 finished with value: 0.7072667480717113 and parameters: {'penalty': 'l1', 'C': 0.4812667212168102, 'l1_ratio': 0.9008288032625884}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  86%|████████▌ | 172/200 [09:03<01:44]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:02,173] Trial 172 finished with value: 0.7079152788763432 and parameters: {'penalty': 'l1', 'C': 0.3369259781287107, 'l1_ratio': 0.8805760339027571}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  86%|████████▋ | 173/200 [09:04<01:23]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:05,363] Trial 173 finished with value: 0.7072500155305449 and parameters: {'penalty': 'l1', 'C': 0.563646990910324, 'l1_ratio': 0.8518235974892571}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  87%|████████▋ | 174/200 [09:08<01:21]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:24:12,190] Trial 174 finished with value: 0.7080062121770039 and parameters: {'penalty': 'l1', 'C': 1.201382400045721, 'l1_ratio': 0.9812367679506506}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  88%|████████▊ | 175/200 [09:14<01:45]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:15,185] Trial 175 finished with value: 0.7074288641521727 and parameters: {'penalty': 'l1', 'C': 0.4244370802016763, 'l1_ratio': 0.6143262337075845}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  88%|████████▊ | 176/200 [09:17<01:32]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:24:21,182] Trial 176 finished with value: 0.7132898268951456 and parameters: {'penalty': 'l1', 'C': 60.11138890018849, 'l1_ratio': 0.9031095965579019}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  88%|████████▊ | 177/200 [09:23<01:43]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:24,555] Trial 177 finished with value: 0.7075985705228927 and parameters: {'penalty': 'l1', 'C': 0.7347122822880325, 'l1_ratio': 0.9320524450775525}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  89%|████████▉ | 178/200 [09:27<01:31]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:25,691] Trial 178 finished with value: 0.7089001932442187 and parameters: {'penalty': 'l1', 'C': 0.20370729485626185, 'l1_ratio': 0.8353035128412621}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  90%|████████▉ | 179/200 [09:28<01:08]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:30,411] Trial 179 finished with value: 0.7071952882639423 and parameters: {'penalty': 'l1', 'C': 0.5377657300807007, 'l1_ratio': 0.9636752093737482}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  90%|█████████ | 180/200 [09:33<01:13]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:24:36,386] Trial 180 finished with value: 0.7097308396200798 and parameters: {'penalty': 'elasticnet', 'C': 2.030808173574461, 'l1_ratio': 0.9613406486743524}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  90%|█████████ | 181/200 [09:39<01:23]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:39,832] Trial 181 finished with value: 0.7072073460742622 and parameters: {'penalty': 'l1', 'C': 0.5435345207415015, 'l1_ratio': 0.9895079568391095}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  91%|█████████ | 182/200 [09:42<01:13]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:44,939] Trial 182 finished with value: 0.7074041563604835 and parameters: {'penalty': 'l1', 'C': 0.6448743656346694, 'l1_ratio': 0.9899004204110684}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  92%|█████████▏| 183/200 [09:47<01:14]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:46,848] Trial 183 finished with value: 0.7080406981053455 and parameters: {'penalty': 'l1', 'C': 0.3239370158450624, 'l1_ratio': 0.9978509159904966}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  92%|█████████▏| 184/200 [09:49<00:58]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:51,804] Trial 184 finished with value: 0.7076299201711446 and parameters: {'penalty': 'l1', 'C': 0.8785420807356576, 'l1_ratio': 0.965959533619781}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  92%|█████████▎| 185/200 [09:54<01:00]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:55,328] Trial 185 finished with value: 0.7072597443424806 and parameters: {'penalty': 'l1', 'C': 0.4843984626610911, 'l1_ratio': 0.4927808484330438}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  93%|█████████▎| 186/200 [09:58<00:54]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:58,178] Trial 186 finished with value: 0.7075324232101197 and parameters: {'penalty': 'l1', 'C': 0.39780356889238705, 'l1_ratio': 0.40498392891021184}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  94%|█████████▎| 187/200 [10:00<00:46]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:24:59,158] Trial 187 finished with value: 0.7084260749198742 and parameters: {'penalty': 'l1', 'C': 0.2685380846579334, 'l1_ratio': 0.9474885699306566}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  94%|█████████▍| 188/200 [10:01<00:33]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:02,453] Trial 188 finished with value: 0.7073120633419827 and parameters: {'penalty': 'l1', 'C': 0.5949206523220709, 'l1_ratio': 0.9809398212874568}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  94%|█████████▍| 189/200 [10:05<00:32]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2024-10-08 13:25:08,233] Trial 189 finished with value: 0.7075931528796524 and parameters: {'penalty': 'l1', 'C': 0.9763521153062696, 'l1_ratio': 0.9201811627761644}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  95%|█████████▌| 190/200 [10:10<00:37]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:08,423] Trial 190 finished with value: 0.7810242747318844 and parameters: {'penalty': 'l1', 'C': 0.0045699500590598635, 'l1_ratio': 0.9447015119283968}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  96%|█████████▌| 191/200 [10:11<00:24]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:13,277] Trial 191 finished with value: 0.7072366911364895 and parameters: {'penalty': 'l1', 'C': 0.49530503311034846, 'l1_ratio': 0.8731182602060336}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  96%|█████████▌| 192/200 [10:16<00:26]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:16,293] Trial 192 finished with value: 0.7071789106480133 and parameters: {'penalty': 'l1', 'C': 0.5274325453421983, 'l1_ratio': 0.8717165870155317}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  96%|█████████▋| 193/200 [10:19<00:22]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:17,560] Trial 193 finished with value: 0.7075735172938412 and parameters: {'penalty': 'l1', 'C': 0.388458243854927, 'l1_ratio': 0.8731694021098514}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  97%|█████████▋| 194/200 [10:20<00:15]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:20,864] Trial 194 finished with value: 0.7075740103642499 and parameters: {'penalty': 'l1', 'C': 0.722932245330087, 'l1_ratio': 0.8520114781801386}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  98%|█████████▊| 195/200 [10:23<00:14]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:24,513] Trial 195 finished with value: 0.7072347291458714 and parameters: {'penalty': 'l1', 'C': 0.4962887762423563, 'l1_ratio': 0.9083871054741627}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  98%|█████████▊| 196/200 [10:27<00:12]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:26,426] Trial 196 finished with value: 0.7077915520418836 and parameters: {'penalty': 'l1', 'C': 0.35129900895345945, 'l1_ratio': 0.8969114242066576}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  98%|█████████▊| 197/200 [10:29<00:08]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","[I 2024-10-08 13:25:27,716] Trial 197 finished with value: 0.7081715387698098 and parameters: {'penalty': 'l2', 'C': 0.5077159135743227, 'l1_ratio': 0.8706211112483375}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization:  99%|█████████▉| 198/200 [10:30<00:04]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:31,096] Trial 198 finished with value: 0.7076421665932264 and parameters: {'penalty': 'l1', 'C': 0.7561722009162171, 'l1_ratio': 0.817140644410751}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization: 100%|█████████▉| 199/200 [10:33<00:02]/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n","[I 2024-10-08 13:25:31,989] Trial 199 finished with value: 0.708577220907074 and parameters: {'penalty': 'l1', 'C': 0.24233323636712856, 'l1_ratio': 0.8356200283598993}. Best is trial 101 with value: 0.707178574793981.\n","Optuna Optimization: 100%|██████████| 200/200 [10:34<00:00]\n"]}]},{"cell_type":"code","source":["print(\"Best trial:\")\n","trial = study.best_trial\n","\n","print(f\"  Value: {trial.value}\")\n","print(\"  Params:\")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZj-OoTy_9oA","executionInfo":{"status":"ok","timestamp":1728393984138,"user_tz":-180,"elapsed":321,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}},"outputId":"d9f00e6b-3542-4f2d-8f15-8f919fda4032"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value: 0.707178574793981\n","  Params:\n","    penalty: l1\n","    C: 0.5276546058877624\n","    l1_ratio: 0.9953593630180491\n"]}]},{"cell_type":"markdown","source":["Train the Logistic Regression model using the best hyperparameters found by Optuna, then save the trained model for future use."],"metadata":{"id":"Ql1JqL7PAWX1"}},{"cell_type":"code","source":["logreg_model = LogisticRegression(\n","        penalty = 'l1',\n","        C = 0.5276546058877624,\n","        solver = 'saga',\n","        l1_ratio = 0.9953593630180491,\n","        max_iter = 1000,\n","        random_state = 97\n","    )\n","\n","logreg_model.fit(X_train_transformed, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":152},"id":"kNElcFrGACjk","executionInfo":{"status":"ok","timestamp":1728394006860,"user_tz":-180,"elapsed":7015,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}},"outputId":"45d89099-509e-4b8f-b1b2-7c2d43580d27"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1197: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=0.5276546058877624, l1_ratio=0.9953593630180491,\n","                   max_iter=1000, penalty='l1', random_state=97, solver='saga')"],"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.5276546058877624, l1_ratio=0.9953593630180491,\n","                   max_iter=1000, penalty=&#x27;l1&#x27;, random_state=97, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.5276546058877624, l1_ratio=0.9953593630180491,\n","                   max_iter=1000, penalty=&#x27;l1&#x27;, random_state=97, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["pipeline = Pipeline(steps = [\n","    ('preprocessor', preprocessor),\n","    ('logreg', logreg_model)\n","])"],"metadata":{"id":"q20W4hQrgaNX","executionInfo":{"status":"ok","timestamp":1728394022772,"user_tz":-180,"elapsed":307,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["dump(pipeline, (BASIC_PATH+MODEL_PATH+'logistic_regression_pipeline_with_model.joblib'))"],"metadata":{"id":"stKliXNaAMlb","executionInfo":{"status":"ok","timestamp":1728394024227,"user_tz":-180,"elapsed":288,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"39c57139-a0a8-412f-a9f0-ef188a5e43e5"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/gdrive/MyDrive/ML/projects/feedback-prize/2nd_level_models/logistic_regression_pipeline_with_model.joblib']"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Load the pipeline and evaluate the final metrics on the test set."],"metadata":{"id":"C7n_0WeJMWqU"}},{"cell_type":"code","source":["logreg_pipeline = load(BASIC_PATH+MODEL_PATH+'logistic_regression_pipeline_with_model.joblib')"],"metadata":{"id":"dvmRenOZBa09","executionInfo":{"status":"ok","timestamp":1728394027427,"user_tz":-180,"elapsed":305,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["test_probs = logreg_pipeline.predict_proba(test_df)\n","test_preds = test_probs.argmax(-1)\n","Counter(test_preds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xktsKRsp8jWD","executionInfo":{"status":"ok","timestamp":1728394029347,"user_tz":-180,"elapsed":281,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}},"outputId":"1a867b15-7f75-4f9c-9f54-221aeb7cd770"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({0: 4019, 1: 1360, 2: 482})"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["print('Test metrics:')\n","print(f\"Loss: {log_loss(y_test, test_probs)}\")\n","print(f\"Precision: {precision_score(y_test, test_preds, average = 'macro')}\")\n","print(f\"Recall: {recall_score(y_test, test_preds, average = 'macro')}\")\n","print(f\"F1: {f1_score(y_test, test_preds, average = 'macro')}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVWbIPooBnbU","executionInfo":{"status":"ok","timestamp":1728394032006,"user_tz":-180,"elapsed":450,"user":{"displayName":"Дмитрий Волобуев","userId":"01483900325096357641"}},"outputId":"a704c7c3-51df-48f8-f1a5-426315c58fed"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Test metrics:\n","Loss: 0.6835903988059158\n","Precision: 0.6609212962858931\n","Recall: 0.5885780373436105\n","F1: 0.6053336100336718\n"]}]},{"cell_type":"markdown","source":["After fitting the second-level model, we achieved a slight improvement in the multiclass log loss, which is the target metric in the competition, compared to the first-level models. More importantly, we also observed an overall enhancement in other key metrics. Although this research isn't focused on creating a competition solution, but rather on compiling various NLP techniques, the results are promising. Please also keep in mind that I used a significant portion of the original data for testing purposes as part of this research. In a competition scenario, that data would typically be included in the training or holdout set for training the second-level model, with the final quality assessed on the hidden competition test set. By building on these methods and incorporating a few of your own ideas, there's a good chance of further improving the target metric."],"metadata":{"id":"WCSxry2fNoRt"}}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOgc0rEwwmCF4xlwqtsN4SR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}